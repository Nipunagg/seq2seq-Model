{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Dense,Embedding,LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0  politicians do not have permission to do what ...   \n",
       "1         I'd like to tell you about one such child,   \n",
       "2  This percentage is even greater than the perce...   \n",
       "3  what we really mean is that they're bad at not...   \n",
       "4  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('trans.csv')\n",
    "df.drop('source',inplace=True,axis=1)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,string\n",
    "exclude=set(string.punctuation)\n",
    "def clear_Sentence(x):\n",
    "    x=x.lower();\n",
    "    x=re.sub(\"'\",\"\",x);\n",
    "    x=x.strip()\n",
    "    pat=r'[0-9]'\n",
    "    x=re.sub(pat,'',x)\n",
    "    x=re.sub(\" +\",\" \",x);\n",
    "    x=re.sub(\"[२३०८१५७९४६]\", \"\", x)\n",
    "    temp=[txt for txt in x if txt not in exclude]\n",
    "    x=''.join(temp);  \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(n=10000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>englen</th>\n",
       "      <th>hinlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was a little uncomfortable for them</td>\n",
       "      <td>थोडा कठिन था।</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>headind kaun banega crorepati</td>\n",
       "      <td>शीर्षक कौन बनेगा करोड़पति kaun banega crorepati</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oraiya district</td>\n",
       "      <td>औरैया जिला</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just as the poets and writers described</td>\n",
       "      <td>जैसे कवियों और लेखकों ने वर्णन किया है</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the rich flora of central america is under thr...</td>\n",
       "      <td>मध्य अमेरिकी बहुमूल्य वनस्पति खतरे में है</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is transmitted generation from generation</td>\n",
       "      <td>पीढी दर पीढी चलती आ रही है</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>regisred post</td>\n",
       "      <td>डाकटिकट</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>die a year from diarrhea</td>\n",
       "      <td>हर साल दस्त के रोग से मरते हैं</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the first is the fall of granada</td>\n",
       "      <td>पहली तो ग्रानादा का ध्वस्त होना</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the innovations</td>\n",
       "      <td>नये प्रयोगों से</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0                was a little uncomfortable for them   \n",
       "1                      headind kaun banega crorepati   \n",
       "2                                    oraiya district   \n",
       "3            just as the poets and writers described   \n",
       "4  the rich flora of central america is under thr...   \n",
       "5          is transmitted generation from generation   \n",
       "6                                      regisred post   \n",
       "7                           die a year from diarrhea   \n",
       "8                   the first is the fall of granada   \n",
       "9                                    the innovations   \n",
       "\n",
       "                                    hindi_sentence  englen  hinlen  \n",
       "0                                    थोडा कठिन था।       6       3  \n",
       "1  शीर्षक कौन बनेगा करोड़पति kaun banega crorepati       4       7  \n",
       "2                                       औरैया जिला       2       2  \n",
       "3           जैसे कवियों और लेखकों ने वर्णन किया है       7       8  \n",
       "4       मध्य अमेरिकी बहुमूल्य वनस्पति खतरे में है       10       8  \n",
       "5                       पीढी दर पीढी चलती आ रही है       5       7  \n",
       "6                                          डाकटिकट       2       1  \n",
       "7                   हर साल दस्त के रोग से मरते हैं       5       8  \n",
       "8                  पहली तो ग्रानादा का ध्वस्त होना       7       6  \n",
       "9                                  नये प्रयोगों से       2       3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english_sentence']=df['english_sentence'].apply(lambda x: clear_Sentence(x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: clear_Sentence(x))\n",
    "df['englen']=df['english_sentence'].apply(lambda x: len(x.split(\" \")))\n",
    "df['hinlen']=df['hindi_sentence'].apply(lambda x: len(x.split(\" \")))\n",
    "df=df[df['hinlen']<=10]\n",
    "df=df[df['englen']<=10]\n",
    "#df.drop('index',axis=1,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'headind kaun banega crorepati'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english_sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english=[]\n",
    "hindi=[]\n",
    "for i in range(0,3000):\n",
    "    english.append(df['english_sentence'][i])\n",
    "    hindi.append('<sos> '+df['hindi_sentence'][i]+' <eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4377, 4942)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishwords=set()\n",
    "hindiwords=set()\n",
    "for txt in english:\n",
    "    txt=txt.split(\" \")\n",
    "    for word in txt:\n",
    "        if word not in englishwords:\n",
    "            englishwords.add(word)\n",
    "hindiwords.add('<sos>')\n",
    "hindiwords.add('<eos>')\n",
    "for txt in hindi:\n",
    "    txt=txt.split(\" \")\n",
    "    for word in txt:\n",
    "        if word not in hindiwords:\n",
    "            hindiwords.add(word)  \n",
    "englishwords=sorted(list(englishwords))\n",
    "hindiwords=sorted(list(hindiwords))\n",
    "\n",
    "len(englishwords),len(hindiwords)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> थोडा कठिन था। <eos>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxenglength=max([len(str(txt).split(\" \")) for txt in english])\n",
    "maxhinlength=max([len(str(txt).split(\" \")) for txt in hindi])\n",
    "print(maxenglength,maxhinlength)\n",
    "type(maxenglength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvoc_size=4000\\nonehotrepresent=[one_hot(str(txt),voc_size) for txt in english]\\nonehotrepresent[0]\\ntotal_length=2300\\npadrepresentation=pad_sequences(onehotrepresent,padding='post',maxlen=total_length)\\npadrepresentation[0]\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "voc_size=4000\n",
    "onehotrepresent=[one_hot(str(txt),voc_size) for txt in english]\n",
    "onehotrepresent[0]\n",
    "total_length=2300\n",
    "padrepresentation=pad_sequences(onehotrepresent,padding='post',maxlen=total_length)\n",
    "padrepresentation[0]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict=dict([(word,i) for i,word in enumerate(englishwords)])\n",
    "decoder_dict=dict([(word,i) for i,word in enumerate(hindiwords)])\n",
    "reverse_input_dict=dict((i,word) for word,i in encoder_dict.items())\n",
    "reverse_target_dict=dict((i,word) for word,i in decoder_dict.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input=np.zeros((3000,maxenglength,len(englishwords)),dtype='float32')\n",
    "decoder_input=np.zeros((3000,maxhinlength,len(hindiwords)),dtype='float32')\n",
    "decoder_target=np.zeros((3000,maxhinlength,len(hindiwords)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(engtext,hintext) in enumerate(zip(english,hindi)):\n",
    "    if(i>=3000):\n",
    "        break;\n",
    "    for t,txt in enumerate(engtext.split()):\n",
    "        encoder_input[i,t,encoder_dict[txt]]=1;   \n",
    "    for t,txt in enumerate(hintext.split()):\n",
    "        decoder_input[i,t,decoder_dict[txt]]=1;\n",
    "        if(t>0):\n",
    "            decoder_target[i,t-1,decoder_dict[txt]]=1;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 10, 4377), (3000, 12, 4942), (3000, 12, 4942))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape,decoder_input.shape,decoder_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=128\n",
    "epoch=100\n",
    "features=256\n",
    "latent_dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "#input_encoder=Input(shape=(None,))\n",
    "input_encoder=Input(shape=(None,len(englishwords)))\n",
    "emb_enc=Embedding(len(englishwords),latent_dim)(input_encoder)\n",
    "lstmlayer=LSTM(features,return_state=True)\n",
    "#output,hidden_s,cell_s=lstmlayer(emb_enc)\n",
    "output,hidden_s,cell_s=lstmlayer(input_encoder)\n",
    "encoder_states=[hidden_s,cell_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "input_decoder=Input(shape=(None,len(hindiwords)))\n",
    "#input_decoder=Input(shape=(None,))\n",
    "emb_dec=Embedding(len(hindiwords),latent_dim)(input_decoder)\n",
    "lstmdecoderlayer=LSTM(features,return_sequences=True,return_state=True)\n",
    "output,_,_=lstmdecoderlayer(input_decoder,initial_state=encoder_states)\n",
    "#output,_,_=lstmdecoderlayer(emb_dec,initial_state=encoder_states)\n",
    "denselayer=Dense(len(hindiwords),activation='softmax')\n",
    "output=denselayer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 4377)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 4942)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 4745216     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  5323776     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 4942)   1270094     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 11,339,086\n",
      "Trainable params: 11,339,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model([input_encoder,input_decoder],output)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 157ms/step - loss: 4.7490 - accuracy: 0.0601 - val_loss: 3.8752 - val_accuracy: 0.0833\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.6691 - accuracy: 0.0833 - val_loss: 3.8625 - val_accuracy: 0.0833\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 3.5710 - accuracy: 0.0833 - val_loss: 3.9283 - val_accuracy: 0.0833\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.5656 - accuracy: 0.0834 - val_loss: 3.8790 - val_accuracy: 0.0903\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.5788 - accuracy: 0.0905 - val_loss: 3.8902 - val_accuracy: 0.0903\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.5447 - accuracy: 0.0901 - val_loss: 3.9011 - val_accuracy: 0.0904\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 3.5005 - accuracy: 0.0913 - val_loss: 3.9065 - val_accuracy: 0.0906\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4881 - accuracy: 0.0910 - val_loss: 3.9094 - val_accuracy: 0.0906\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 3.4712 - accuracy: 0.0910 - val_loss: 3.9220 - val_accuracy: 0.0907\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4526 - accuracy: 0.0911 - val_loss: 3.9187 - val_accuracy: 0.0909\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.4598 - accuracy: 0.0915 - val_loss: 3.9234 - val_accuracy: 0.0907\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4628 - accuracy: 0.0914 - val_loss: 3.9295 - val_accuracy: 0.0916\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4535 - accuracy: 0.0922 - val_loss: 3.9364 - val_accuracy: 0.0921\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 3.4332 - accuracy: 0.0941 - val_loss: 3.9374 - val_accuracy: 0.0925\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.4340 - accuracy: 0.0948 - val_loss: 3.9350 - val_accuracy: 0.0928\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4093 - accuracy: 0.0938 - val_loss: 3.9422 - val_accuracy: 0.0937\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.3840 - accuracy: 0.0958 - val_loss: 3.9387 - val_accuracy: 0.0928\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.4141 - accuracy: 0.0962 - val_loss: 3.9491 - val_accuracy: 0.0922\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.3998 - accuracy: 0.0972 - val_loss: 3.9469 - val_accuracy: 0.0932\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.3874 - accuracy: 0.0987 - val_loss: 3.9469 - val_accuracy: 0.0937\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.3521 - accuracy: 0.0991 - val_loss: 3.9502 - val_accuracy: 0.0924\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.3113 - accuracy: 0.0986 - val_loss: 3.9525 - val_accuracy: 0.0936\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.3216 - accuracy: 0.0998 - val_loss: 3.9547 - val_accuracy: 0.0927\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.3000 - accuracy: 0.0997 - val_loss: 3.9602 - val_accuracy: 0.0927\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 3.3307 - accuracy: 0.1005 - val_loss: 3.9536 - val_accuracy: 0.0931\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.2721 - accuracy: 0.1006 - val_loss: 3.9602 - val_accuracy: 0.0931\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.3038 - accuracy: 0.1023 - val_loss: 3.9707 - val_accuracy: 0.0923\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.2467 - accuracy: 0.1021 - val_loss: 3.9699 - val_accuracy: 0.0923\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.2737 - accuracy: 0.1018 - val_loss: 3.9691 - val_accuracy: 0.0932\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.2932 - accuracy: 0.1019 - val_loss: 3.9604 - val_accuracy: 0.0922\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.2258 - accuracy: 0.1034 - val_loss: 3.9781 - val_accuracy: 0.0925\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 3.2375 - accuracy: 0.1028 - val_loss: 3.9713 - val_accuracy: 0.0922\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1910 - accuracy: 0.1038 - val_loss: 3.9762 - val_accuracy: 0.0916\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1957 - accuracy: 0.1056 - val_loss: 3.9814 - val_accuracy: 0.0910\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1835 - accuracy: 0.1061 - val_loss: 3.9822 - val_accuracy: 0.0922\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1991 - accuracy: 0.1056 - val_loss: 3.9846 - val_accuracy: 0.0919\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 3.1979 - accuracy: 0.1080 - val_loss: 3.9835 - val_accuracy: 0.0915\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.1593 - accuracy: 0.1056 - val_loss: 3.9910 - val_accuracy: 0.0919\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1070 - accuracy: 0.1094 - val_loss: 3.9982 - val_accuracy: 0.0911\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 3.1046 - accuracy: 0.1105 - val_loss: 3.9923 - val_accuracy: 0.0913\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.1378 - accuracy: 0.1107 - val_loss: 4.0001 - val_accuracy: 0.0921\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 3.0930 - accuracy: 0.1116 - val_loss: 4.0020 - val_accuracy: 0.0918\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.0376 - accuracy: 0.1141 - val_loss: 4.0089 - val_accuracy: 0.0905\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.9774 - accuracy: 0.1165 - val_loss: 3.9976 - val_accuracy: 0.0908\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 3.0342 - accuracy: 0.1181 - val_loss: 4.0002 - val_accuracy: 0.0925\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 2.9809 - accuracy: 0.1201 - val_loss: 4.0000 - val_accuracy: 0.0931\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.9977 - accuracy: 0.1196 - val_loss: 4.0040 - val_accuracy: 0.0924\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.9834 - accuracy: 0.1234 - val_loss: 4.0064 - val_accuracy: 0.0930\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.8782 - accuracy: 0.1259 - val_loss: 4.0056 - val_accuracy: 0.0918\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 2.8956 - accuracy: 0.1258 - val_loss: 4.0076 - val_accuracy: 0.0917\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.8881 - accuracy: 0.1297 - val_loss: 4.0104 - val_accuracy: 0.0913\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.8687 - accuracy: 0.1307 - val_loss: 4.0124 - val_accuracy: 0.0919\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.8297 - accuracy: 0.1311 - val_loss: 4.0044 - val_accuracy: 0.0922\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.8493 - accuracy: 0.1364 - val_loss: 4.0366 - val_accuracy: 0.0924\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.7828 - accuracy: 0.1384 - val_loss: 4.0179 - val_accuracy: 0.0928\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.7924 - accuracy: 0.1404 - val_loss: 4.0278 - val_accuracy: 0.0925\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 2.7468 - accuracy: 0.1398 - val_loss: 4.0285 - val_accuracy: 0.0930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 2.7184 - accuracy: 0.1453 - val_loss: 4.0092 - val_accuracy: 0.0923\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.7139 - accuracy: 0.1476 - val_loss: 4.0183 - val_accuracy: 0.0941\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 2.6668 - accuracy: 0.1491 - val_loss: 4.0182 - val_accuracy: 0.0912\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.6383 - accuracy: 0.1528 - val_loss: 4.0338 - val_accuracy: 0.0944\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.6099 - accuracy: 0.1532 - val_loss: 4.0255 - val_accuracy: 0.0934\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.5915 - accuracy: 0.1554 - val_loss: 4.0342 - val_accuracy: 0.0957\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.5822 - accuracy: 0.1593 - val_loss: 4.0349 - val_accuracy: 0.0934\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.5856 - accuracy: 0.1656 - val_loss: 4.0375 - val_accuracy: 0.0942\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.5261 - accuracy: 0.1660 - val_loss: 4.0367 - val_accuracy: 0.0942\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.4676 - accuracy: 0.1708 - val_loss: 4.0412 - val_accuracy: 0.0937\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.4670 - accuracy: 0.1750 - val_loss: 4.0440 - val_accuracy: 0.0946\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.4097 - accuracy: 0.1752 - val_loss: 4.0521 - val_accuracy: 0.0938\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.3602 - accuracy: 0.1775 - val_loss: 4.0543 - val_accuracy: 0.0958\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.3653 - accuracy: 0.1800 - val_loss: 4.0561 - val_accuracy: 0.0961\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 2.3146 - accuracy: 0.1821 - val_loss: 4.0568 - val_accuracy: 0.0934\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.3132 - accuracy: 0.1885 - val_loss: 4.0697 - val_accuracy: 0.0956\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.2313 - accuracy: 0.1927 - val_loss: 4.0720 - val_accuracy: 0.0961\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.2052 - accuracy: 0.1936 - val_loss: 4.0703 - val_accuracy: 0.0948\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.2225 - accuracy: 0.2007 - val_loss: 4.0810 - val_accuracy: 0.0956\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 2.1734 - accuracy: 0.2015 - val_loss: 4.0791 - val_accuracy: 0.0966\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 2.1606 - accuracy: 0.2104 - val_loss: 4.0861 - val_accuracy: 0.0966\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.0917 - accuracy: 0.2118 - val_loss: 4.0899 - val_accuracy: 0.0978\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.0517 - accuracy: 0.2171 - val_loss: 4.0865 - val_accuracy: 0.0967\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 2.0349 - accuracy: 0.2212 - val_loss: 4.0986 - val_accuracy: 0.0963\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 1.9815 - accuracy: 0.2301 - val_loss: 4.0970 - val_accuracy: 0.0955\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.9373 - accuracy: 0.2349 - val_loss: 4.1153 - val_accuracy: 0.0944\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.9229 - accuracy: 0.2393 - val_loss: 4.1254 - val_accuracy: 0.0950\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.8831 - accuracy: 0.2419 - val_loss: 4.1176 - val_accuracy: 0.0959\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 1.8397 - accuracy: 0.2435 - val_loss: 4.1229 - val_accuracy: 0.0951\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 1.8250 - accuracy: 0.2480 - val_loss: 4.1357 - val_accuracy: 0.0958\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.7923 - accuracy: 0.2572 - val_loss: 4.1343 - val_accuracy: 0.0964\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 1.7687 - accuracy: 0.2587 - val_loss: 4.1398 - val_accuracy: 0.0962\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.7291 - accuracy: 0.2665 - val_loss: 4.1410 - val_accuracy: 0.0956\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 1.7172 - accuracy: 0.2725 - val_loss: 4.1527 - val_accuracy: 0.0958\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.6558 - accuracy: 0.2739 - val_loss: 4.1592 - val_accuracy: 0.0961\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.6380 - accuracy: 0.2813 - val_loss: 4.1621 - val_accuracy: 0.0956\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.6233 - accuracy: 0.2875 - val_loss: 4.1705 - val_accuracy: 0.0956\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.5922 - accuracy: 0.2903 - val_loss: 4.1829 - val_accuracy: 0.0954\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.5789 - accuracy: 0.2950 - val_loss: 4.1787 - val_accuracy: 0.0956\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.5427 - accuracy: 0.2981 - val_loss: 4.1863 - val_accuracy: 0.0955\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.4680 - accuracy: 0.2994 - val_loss: 4.1955 - val_accuracy: 0.0959\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 1.4706 - accuracy: 0.3113 - val_loss: 4.2057 - val_accuracy: 0.0956\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 2s 98ms/step - loss: 1.4486 - accuracy: 0.3112 - val_loss: 4.2085 - val_accuracy: 0.0968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24c088ad508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input,decoder_input],decoder_target,batch_size=batch,epochs=epoch,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference model\n",
    "\n",
    "encoder_model = Model(input_encoder, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(features,))\n",
    "decoder_state_input_c = Input(shape=(features,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = lstmdecoderlayer(input_decoder, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = denselayer(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([input_decoder] + decoder_states_inputs,[decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1,len(hindiwords)))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0,decoder_dict['<sos>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_dict[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > maxhinlength):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1,len(hindiwords)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=\"there is justice\"\n",
    "temp=np.zeros((1,maxenglength,len(englishwords)),dtype='float32')\n",
    "for t,txt in enumerate(str.split()):\n",
    "        temp[0,t,encoder_dict[txt]]=1; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentence = decode_sequence(temp)\n",
    "print(decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
