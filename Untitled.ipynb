{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Dense,Embedding,LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d8cd39b22d9f>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0  politicians do not have permission to do what ...   \n",
       "1         I'd like to tell you about one such child,   \n",
       "2  This percentage is even greater than the perce...   \n",
       "3  what we really mean is that they're bad at not...   \n",
       "4  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('trans.csv')\n",
    "df.drop('source',inplace=True,axis=1)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(20000,random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,string\n",
    "exclude=set(string.punctuation)\n",
    "def clear_Sentence(x):\n",
    "    x=x.lower();\n",
    "    x=re.sub(\"'\",\"\",x);\n",
    "    x=x.strip()\n",
    "    pat=r'[0-9]'\n",
    "    x=re.sub(pat,'',x)\n",
    "    x=re.sub(\" +\",\" \",x);\n",
    "    x=re.sub(\"[२३०८१५७९४६]\", \"\", x)\n",
    "    temp=[txt for txt in x if txt not in exclude]\n",
    "    x=''.join(temp);  \n",
    "    return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>englen</th>\n",
       "      <th>hinlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was a little uncomfortable for them</td>\n",
       "      <td>थोडा कठिन था।</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no fees is to be paid for filing the appeal to...</td>\n",
       "      <td>अधिकरण में अपील करने के लिए कोई फीस नहीं देनी ...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>headind kaun banega crorepati</td>\n",
       "      <td>शीर्षक कौन बनेगा करोड़पति kaun banega crorepati</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oraiya district</td>\n",
       "      <td>औरैया जिला</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the government develops and the government ...</td>\n",
       "      <td>अगर सरकार ही उन्हे बनाए और सरकार ही उनका प्रयो...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>just as the poets and writers described</td>\n",
       "      <td>जैसे कवियों और लेखकों ने वर्णन किया है</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the rich flora of central america is under thr...</td>\n",
       "      <td>मध्य अमेरिकी बहुमूल्य वनस्पति खतरे में है</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>searcheses on research articles in indian univ...</td>\n",
       "      <td>भारतीय विश्वविद्यालयों में संस्कृत पर आधारित श...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is transmitted generation from generation</td>\n",
       "      <td>पीढी दर पीढी चलती आ रही है</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>now he tries e again and that doesnt work</td>\n",
       "      <td>अब वो फिर ई लगाते हैं और वह काम नहीं करता</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0                was a little uncomfortable for them   \n",
       "1  no fees is to be paid for filing the appeal to...   \n",
       "2                      headind kaun banega crorepati   \n",
       "3                                    oraiya district   \n",
       "4  if the government develops and the government ...   \n",
       "5            just as the poets and writers described   \n",
       "6  the rich flora of central america is under thr...   \n",
       "7  searcheses on research articles in indian univ...   \n",
       "8          is transmitted generation from generation   \n",
       "9          now he tries e again and that doesnt work   \n",
       "\n",
       "                                      hindi_sentence  englen  hinlen  \n",
       "0                                      थोडा कठिन था।       6       3  \n",
       "1  अधिकरण में अपील करने के लिए कोई फीस नहीं देनी ...      14      12  \n",
       "2    शीर्षक कौन बनेगा करोड़पति kaun banega crorepati       4       7  \n",
       "3                                         औरैया जिला       2       2  \n",
       "4  अगर सरकार ही उन्हे बनाए और सरकार ही उनका प्रयो...       9      11  \n",
       "5             जैसे कवियों और लेखकों ने वर्णन किया है       7       8  \n",
       "6         मध्य अमेरिकी बहुमूल्य वनस्पति खतरे में है       10       8  \n",
       "7  भारतीय विश्वविद्यालयों में संस्कृत पर आधारित श...      10      13  \n",
       "8                         पीढी दर पीढी चलती आ रही है       5       7  \n",
       "9          अब वो फिर ई लगाते हैं और वह काम नहीं करता       9      11  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english_sentence']=df['english_sentence'].apply(lambda x: clear_Sentence(x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: clear_Sentence(x))\n",
    "df['englen']=df['english_sentence'].apply(lambda x: len(x.split(\" \")))\n",
    "df['hinlen']=df['hindi_sentence'].apply(lambda x: len(x.split(\" \")))\n",
    "df=df[df['hinlen']<=15]\n",
    "df=df[df['englen']<=15]\n",
    "df=df[df['hinlen']>=1]\n",
    "df=df[df['englen']>=1]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no fees is to be paid for filing the appeal to this tribunal '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english_sentence'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: str(x))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english_sentence'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "english=[]\n",
    "hindi=[]\n",
    "for i in range(0,len(df)):\n",
    "    str1 =df['english_sentence'][i]\n",
    "    str2='<sos> '+ df['hindi_sentence'][i] +' <eos>'\n",
    "    english.append(str1)\n",
    "    hindi.append(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputwords=set()\n",
    "targetwords=set()\n",
    "for txt in english:\n",
    "    txt=txt.split(\" \")\n",
    "    for word in txt:\n",
    "        if word not in inputwords:\n",
    "            inputwords.add(word)\n",
    "for txt in hindi:\n",
    "    txt=txt.split(\" \")\n",
    "    for word in txt:\n",
    "        if word not in targetwords:\n",
    "            targetwords.add(word)  \n",
    "inputwords=sorted(list(inputwords))\n",
    "targetwords=sorted(list(targetwords))\n",
    "\n",
    "\n",
    "num_encoder_tokens=len(inputwords)\n",
    "num_decoder_tokens=len(targetwords) \n",
    "num_decoder_tokens+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> थोडा कठिन था। <eos>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 17\n"
     ]
    }
   ],
   "source": [
    "max_length_src=max([len(str(txt).split(\" \")) for txt in english])\n",
    "max_length_tar=max([len(str(txt).split(\" \")) for txt in hindi])\n",
    "print(max_length_src,max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvoc_size=4000\\nonehotrepresent=[one_hot(str(txt),voc_size) for txt in english]\\nonehotrepresent[0]\\ntotal_length=2300\\npadrepresentation=pad_sequences(onehotrepresent,padding='post',maxlen=total_length)\\npadrepresentation[0]\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "voc_size=4000\n",
    "onehotrepresent=[one_hot(str(txt),voc_size) for txt in english]\n",
    "onehotrepresent[0]\n",
    "total_length=2300\n",
    "padrepresentation=pad_sequences(onehotrepresent,padding='post',maxlen=total_length)\n",
    "padrepresentation[0]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index=dict([(word,i) for i,word in enumerate(inputwords)])\n",
    "target_token_index=dict([(word,i) for i,word in enumerate(targetwords)])\n",
    "reverse_input_char_index=dict((i,word) for word,i in input_token_index.items())\n",
    "reverse_target_char_index=dict((i,word) for word,i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8757,), (2190,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df['english_sentence'], df['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i,(engtext,hintext) in enumerate(zip(english,hindi)):\\n    if(i>=750):\\n        break;\\n    for t,txt in enumerate(engtext.split()):\\n        encoder_input[i,t,encoder_dict[txt]]=1;   \\n    for t,txt in enumerate(hintext.split()):\\n        decoder_input[i,t,decoder_dict[txt]]=1;\\n        if(t>0):\\n            decoder_target[i,t-1,decoder_dict[txt]]=1;\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i,(engtext,hintext) in enumerate(zip(english,hindi)):\n",
    "    if(i>=750):\n",
    "        break;\n",
    "    for t,txt in enumerate(engtext.split()):\n",
    "        encoder_input[i,t,encoder_dict[txt]]=1;   \n",
    "    for t,txt in enumerate(hintext.split()):\n",
    "        decoder_input[i,t,decoder_dict[txt]]=1;\n",
    "        if(t>0):\n",
    "            decoder_target[i,t-1,decoder_dict[txt]]=1;\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_input.shape,decoder_input.shape,decoder_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16667414740026978631\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5060693856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7773358449545593435\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 156)    1824888     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 156)    2074644     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 156), (None, 195312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 156),  195312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 13299)  2087943     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,378,099\n",
      "Trainable params: 6,378,099\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1=train_samples//batch_size\n",
    "st2=val_samples//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aggar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "68/68 [==============================] - 55s 661ms/step - loss: 3.2502 - accuracy: 0.0322 - val_loss: 2.9772 - val_accuracy: 0.0490\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 42s 611ms/step - loss: 2.7198 - accuracy: 0.0483 - val_loss: 2.9848 - val_accuracy: 0.0496\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 42s 614ms/step - loss: 2.6965 - accuracy: 0.0503 - val_loss: 2.9939 - val_accuracy: 0.0518\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 42s 613ms/step - loss: 2.6484 - accuracy: 0.0522 - val_loss: 2.9848 - val_accuracy: 0.0567\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 17s 249ms/step - loss: 2.6166 - accuracy: 0.0580 - val_loss: 2.9657 - val_accuracy: 0.0612\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 15s 217ms/step - loss: 2.5626 - accuracy: 0.0635 - val_loss: 2.9429 - val_accuracy: 0.0674\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 2.5104 - accuracy: 0.0691 - val_loss: 2.9260 - val_accuracy: 0.0713\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 15s 218ms/step - loss: 2.4549 - accuracy: 0.0759 - val_loss: 2.9226 - val_accuracy: 0.0735\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 2.3999 - accuracy: 0.0834 - val_loss: 2.9164 - val_accuracy: 0.0771\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 2.3554 - accuracy: 0.0905 - val_loss: 2.9031 - val_accuracy: 0.0801\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 2.3081 - accuracy: 0.0946 - val_loss: 2.8837 - val_accuracy: 0.0861\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 15s 217ms/step - loss: 2.2714 - accuracy: 0.1013 - val_loss: 2.8807 - val_accuracy: 0.0882\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 15s 215ms/step - loss: 2.2291 - accuracy: 0.1077 - val_loss: 2.8774 - val_accuracy: 0.0911\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 15s 216ms/step - loss: 2.1878 - accuracy: 0.1152 - val_loss: 2.8791 - val_accuracy: 0.0914\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 15s 215ms/step - loss: 2.1330 - accuracy: 0.1221 - val_loss: 2.8681 - val_accuracy: 0.0936\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 15s 216ms/step - loss: 2.0803 - accuracy: 0.1320 - val_loss: 2.8719 - val_accuracy: 0.0953\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 2.0342 - accuracy: 0.1413 - val_loss: 2.8739 - val_accuracy: 0.0971\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 1.9919 - accuracy: 0.1473 - val_loss: 2.8820 - val_accuracy: 0.1005\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 15s 217ms/step - loss: 1.9608 - accuracy: 0.1569 - val_loss: 2.8890 - val_accuracy: 0.0996\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 15s 218ms/step - loss: 1.9258 - accuracy: 0.1658 - val_loss: 2.8835 - val_accuracy: 0.1031\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.8848 - accuracy: 0.1737 - val_loss: 2.8885 - val_accuracy: 0.1052\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 15s 215ms/step - loss: 1.8422 - accuracy: 0.1860 - val_loss: 2.8936 - val_accuracy: 0.1041\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 15s 218ms/step - loss: 1.7986 - accuracy: 0.1981 - val_loss: 2.9020 - val_accuracy: 0.1041\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.7718 - accuracy: 0.2084 - val_loss: 2.9061 - val_accuracy: 0.1065\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 1.7327 - accuracy: 0.2193 - val_loss: 2.9092 - val_accuracy: 0.1074\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 15s 217ms/step - loss: 1.6790 - accuracy: 0.2334 - val_loss: 2.9343 - val_accuracy: 0.1075\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.6378 - accuracy: 0.2457 - val_loss: 2.9372 - val_accuracy: 0.1080\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 15s 218ms/step - loss: 1.6052 - accuracy: 0.2596 - val_loss: 2.9494 - val_accuracy: 0.1095\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 15s 223ms/step - loss: 1.5633 - accuracy: 0.2691 - val_loss: 2.9648 - val_accuracy: 0.1079\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.5181 - accuracy: 0.2863 - val_loss: 2.9657 - val_accuracy: 0.1063\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.4777 - accuracy: 0.3037 - val_loss: 2.9884 - val_accuracy: 0.1081\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 16s 232ms/step - loss: 1.4381 - accuracy: 0.3183 - val_loss: 3.0126 - val_accuracy: 0.1101\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 1.4044 - accuracy: 0.3298 - val_loss: 3.0205 - val_accuracy: 0.1078\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 15s 223ms/step - loss: 1.3761 - accuracy: 0.3471 - val_loss: 3.0255 - val_accuracy: 0.1119\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 15s 218ms/step - loss: 1.3363 - accuracy: 0.3619 - val_loss: 3.0423 - val_accuracy: 0.1107\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 15s 221ms/step - loss: 1.3007 - accuracy: 0.3779 - val_loss: 3.0559 - val_accuracy: 0.1092\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 16s 240ms/step - loss: 1.2638 - accuracy: 0.3968 - val_loss: 3.0698 - val_accuracy: 0.1107\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 1.2348 - accuracy: 0.4098 - val_loss: 3.0830 - val_accuracy: 0.1085\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 1.2064 - accuracy: 0.4279 - val_loss: 3.0836 - val_accuracy: 0.1089\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 1.1639 - accuracy: 0.4481 - val_loss: 3.0858 - val_accuracy: 0.1086\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 15s 221ms/step - loss: 1.1249 - accuracy: 0.4707 - val_loss: 3.0988 - val_accuracy: 0.1115\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.0963 - accuracy: 0.4858 - val_loss: 3.1000 - val_accuracy: 0.1106\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 15s 220ms/step - loss: 1.0650 - accuracy: 0.5011 - val_loss: 3.1159 - val_accuracy: 0.1102\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 15s 219ms/step - loss: 1.0343 - accuracy: 0.5185 - val_loss: 3.1268 - val_accuracy: 0.1116\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 15s 222ms/step - loss: 0.9980 - accuracy: 0.5378 - val_loss: 3.1429 - val_accuracy: 0.1116\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.9549 - accuracy: 0.5529 - val_loss: 3.1459 - val_accuracy: 0.1116\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 15s 223ms/step - loss: 0.9275 - accuracy: 0.5676 - val_loss: 3.1621 - val_accuracy: 0.1115\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 15s 221ms/step - loss: 0.8980 - accuracy: 0.5842 - val_loss: 3.1881 - val_accuracy: 0.1147\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.8655 - accuracy: 0.6029 - val_loss: 3.1910 - val_accuracy: 0.1118\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.8408 - accuracy: 0.6215 - val_loss: 3.2006 - val_accuracy: 0.1118\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 16s 230ms/step - loss: 0.8050 - accuracy: 0.6384 - val_loss: 3.2190 - val_accuracy: 0.1097\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 15s 223ms/step - loss: 0.7821 - accuracy: 0.6495 - val_loss: 3.2351 - val_accuracy: 0.1108\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.7550 - accuracy: 0.6666 - val_loss: 3.2512 - val_accuracy: 0.1120\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.7296 - accuracy: 0.6788 - val_loss: 3.2593 - val_accuracy: 0.1080\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.7048 - accuracy: 0.6905 - val_loss: 3.2769 - val_accuracy: 0.1098\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.6794 - accuracy: 0.7063 - val_loss: 3.2863 - val_accuracy: 0.1110\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 15s 224ms/step - loss: 0.6515 - accuracy: 0.7219 - val_loss: 3.3108 - val_accuracy: 0.1090\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 15s 223ms/step - loss: 0.6229 - accuracy: 0.7355 - val_loss: 3.3340 - val_accuracy: 0.1124\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.5950 - accuracy: 0.7451 - val_loss: 3.3354 - val_accuracy: 0.1100\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.5737 - accuracy: 0.7604 - val_loss: 3.3523 - val_accuracy: 0.1096\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.5488 - accuracy: 0.7709 - val_loss: 3.3692 - val_accuracy: 0.1104\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.5313 - accuracy: 0.7808 - val_loss: 3.3811 - val_accuracy: 0.1110\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 16s 229ms/step - loss: 0.5010 - accuracy: 0.7975 - val_loss: 3.3993 - val_accuracy: 0.1084\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.4834 - accuracy: 0.8058 - val_loss: 3.4074 - val_accuracy: 0.1076\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.4632 - accuracy: 0.8176 - val_loss: 3.4348 - val_accuracy: 0.1092\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.4414 - accuracy: 0.8274 - val_loss: 3.4491 - val_accuracy: 0.1091\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.4272 - accuracy: 0.8350 - val_loss: 3.4627 - val_accuracy: 0.1080\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.4043 - accuracy: 0.8446 - val_loss: 3.4701 - val_accuracy: 0.1086\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.3865 - accuracy: 0.8551 - val_loss: 3.4939 - val_accuracy: 0.1098\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.3654 - accuracy: 0.8656 - val_loss: 3.5110 - val_accuracy: 0.1091\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.3335 - accuracy: 0.8729 - val_loss: 3.5258 - val_accuracy: 0.1089\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.3232 - accuracy: 0.8800 - val_loss: 3.5477 - val_accuracy: 0.1106\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.3091 - accuracy: 0.8859 - val_loss: 3.5476 - val_accuracy: 0.1113\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.2951 - accuracy: 0.8935 - val_loss: 3.5714 - val_accuracy: 0.1092\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 16s 230ms/step - loss: 0.2797 - accuracy: 0.9002 - val_loss: 3.5857 - val_accuracy: 0.1111\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.2630 - accuracy: 0.9084 - val_loss: 3.5994 - val_accuracy: 0.1108\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.2493 - accuracy: 0.9135 - val_loss: 3.6161 - val_accuracy: 0.1088\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.2396 - accuracy: 0.9186 - val_loss: 3.6261 - val_accuracy: 0.1078\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.2272 - accuracy: 0.9257 - val_loss: 3.6415 - val_accuracy: 0.1069\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.2187 - accuracy: 0.9270 - val_loss: 3.6510 - val_accuracy: 0.1084\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 16s 229ms/step - loss: 0.2073 - accuracy: 0.9316 - val_loss: 3.6736 - val_accuracy: 0.1060\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.1956 - accuracy: 0.9390 - val_loss: 3.6916 - val_accuracy: 0.1063\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.1850 - accuracy: 0.9430 - val_loss: 3.6965 - val_accuracy: 0.1067\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.1730 - accuracy: 0.9497 - val_loss: 3.7194 - val_accuracy: 0.1058\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.1628 - accuracy: 0.9528 - val_loss: 3.7345 - val_accuracy: 0.1059\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 15s 224ms/step - loss: 0.1541 - accuracy: 0.9569 - val_loss: 3.7502 - val_accuracy: 0.1045\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.1471 - accuracy: 0.9588 - val_loss: 3.7696 - val_accuracy: 0.1055\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.1404 - accuracy: 0.9622 - val_loss: 3.7775 - val_accuracy: 0.1049\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 16s 228ms/step - loss: 0.1318 - accuracy: 0.9652 - val_loss: 3.7852 - val_accuracy: 0.1029\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 15s 225ms/step - loss: 0.1218 - accuracy: 0.9711 - val_loss: 3.8114 - val_accuracy: 0.1019\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.1164 - accuracy: 0.9711 - val_loss: 3.8365 - val_accuracy: 0.1047\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.1090 - accuracy: 0.9738 - val_loss: 3.8350 - val_accuracy: 0.1056\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.1030 - accuracy: 0.9775 - val_loss: 3.8544 - val_accuracy: 0.1029\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 15s 226ms/step - loss: 0.0978 - accuracy: 0.9789 - val_loss: 3.8605 - val_accuracy: 0.1017\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.0906 - accuracy: 0.9822 - val_loss: 3.8780 - val_accuracy: 0.1039\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.0850 - accuracy: 0.9832 - val_loss: 3.9017 - val_accuracy: 0.1044\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.0807 - accuracy: 0.9844 - val_loss: 3.9025 - val_accuracy: 0.1026\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 15s 227ms/step - loss: 0.0755 - accuracy: 0.9858 - val_loss: 3.9063 - val_accuracy: 0.1053\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 16s 230ms/step - loss: 0.0696 - accuracy: 0.9881 - val_loss: 3.9427 - val_accuracy: 0.1025\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 15s 228ms/step - loss: 0.0636 - accuracy: 0.9899 - val_loss: 3.9459 - val_accuracy: 0.1045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c7af252708>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch =st1,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['<sos>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: they had to turn the spigot entirely off\n",
      "Actual Hindi Translation:  नल्का बिल्कुल बंद करना\n",
      "Predicted Hindi Translation:  और उसके पास आ रहे थे । भाष् एवं भाष् भी भाष् लगभग \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: if theres a child in trouble we beam a gran\n",
      "Actual Hindi Translation: सीबत में एक बच्चा है हम उसे एक दादी देते \n",
      "Predicted Hindi Translation:  में पता लगाने की कोशिश में बहुत ही है” है” है कि ज\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-05b3627a6743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "decoded_sentence = decode_sequence(temp)\n",
    "print(decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
